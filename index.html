
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>调和的微光-HARMONIC GLEAM</title>
  <meta name="author" content="hmgle">

  
  <meta name="description" content="昨天更换手机号码了. 原号码不再使用. 如何获取我的新号码 如果存有我原来的号码: 以原号码为参数运行下面的脚本 #!/bin/sh
if [ "$#" -ne 1 ] ; then echo "Usage: $0 my_old_num"; exit 1;
fi
echo `expr $1 &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://hmgle.github.com">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="/javascripts/ender.js"></script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <link href="/atom.xml" rel="alternate" title="调和的微光-HARMONIC GLEAM" type="application/atom+xml">
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  

</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">调和的微光-HARMONIC GLEAM</a></h1>
  
    <h2>pipe loads the stream, so the stream streams.</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:hmgle.github.com" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2012/05/01/e6898be69cbae58fb7e7a081patch/">手机号码patch</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2012-05-01T00:50:10+08:00" pubdate data-updated="true">May 1<span>st</span>, 2012</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>昨天更换手机号码了. 原号码不再使用.</p>

<h3>如何获取我的新号码</h3>

<ol>
<li>如果存有我原来的号码: 以原号码为参数运行下面的脚本</li>
</ol>


<pre><code>#!/bin/sh
if [ "$#" -ne 1 ] ; then
    echo "Usage: $0 my_old_num";
    exit 1;
fi
echo `expr $1 + \`echo -n MjI2MDgyMDIxNgo= | base64 -d\``
</code></pre>

<ol>
<li>如果没有我原来的号码: 在页面<a href="http_//hmgle.com/archives/21.html">手机号码更换</a>获取我以前的号码, 然后跳转到1.</li>
</ol>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2012/03/17/arme5b9b3e58fb0e4b88be4bd8de59f9fe7bb93e69e84e4bd93e79a84e997aee9a298/">ARM平台下位域结构体的问题</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2012-03-17T15:25:22+08:00" pubdate data-updated="true">Mar 17<span>th</span>, 2012</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>最近在做个IP camera, 开发板是Hi3511的. 在写h.264码流封装成rtp包进行网络传输时, 出问题了: 在客户端用vlc看不到期待的画面. 用wireshark抓包, 把源源不断的rtp包拆包一看, 竟然没有fu-a包, 全是单个的nal包. 而输入的nalu基本都是大于最大传输单元MTU的, 需要分解成fu-a包的形式. 通过测试发现, 问题出现在设置fu分片包的indicator和header上. 再往下分析, 得到在ARM平台下令人惊奇的现象. 假如我们有下面代码:</p>

<pre><code>#include &lt;stdint.h&gt;

typedef struct fu_indicator {
    uint8_t type: 5;
    uint8_t nri: 2;
    uint8_t f: 1;
} fu_indicator_t;

int main(int argc, char **argv)
{
    uint8_t n = 7;
    fu_indicator_t *pstf;

    pstf = (fu_indicator_t *) &amp;n;
    pstf-&gt;type = 0x0f;
    printf("now n is %d\n", n);
    return 0;
}
</code></pre>

<p>以上代码在x86平台上运行结果正如预想的一样, 但在arm平台下就不一样了, 结果竟然是n变成0了. 看汇编内容:</p>

<pre><code>main:
@ args = 0, pretend = 0, frame = 12
@ frame_needed = 1, uses_anonymous_args = 0
mov ip, sp
stmfd sp!, {fp, ip, lr, pc}
sub fp, ip, #4
sub sp, sp, #12
mov r3, #7
strb r3, [fp, #-13]     @ 在内存单元[fp, #-13]地址上保存n=7
sub r3, fp, #13         @ r3放n的地址
str r3, [fp, #-20]      @ 将n的地址保存在内存单元[fp, #-20]上, 即pstf的地址
ldr r2, [fp, #-20]      @ 将n的地址加载到r2上
ldr r1, [r2, #0]        @ 将[r2, #0]的内容即n = 7加载到r1上
str r1, [fp, #-24]      @ 将r1即n = 7保存在[fp, #-24]上
ldr r1, [fp, #-24]      @ 加载地址[fp, #-24]的内容即n = 7到r1
bic r3, r1, #16         @ 将n &amp; ~0x10 = 7 放在r3
orr r3, r3, #15         @ 将7 | 15 = 15 放在r3
str r3, [fp, #-24]      @ 将结果r3 = 15 保存在内存单元[fp, #-24]
ldr r3, [fp, #-24]      @ 加载[fp, #-24] = 15 到r3
str r3, [r2, #0]        @ 保存r3 = 15 到 n的地址[r2, #0]上, 之后n应该=15
ldrb r3, [fp, #-13]     @ zero_extendqisi2
mov r0, r3
sub sp, fp, #12
ldmfd sp, {fp, sp, pc}
.size main, .-main
.ident "GCC: (GNU) 3.4.3 (release) (CodeSourcery ARM Q3cvs 2004)"
</code></pre>

<p>汇编代码文件看起来没有问题, 但问题是程序跑出来的结果n是不等于15的. 这说明出现问题的阶段是发生在编译阶段之后的, 也许是汇编阶段, 也许是链接阶段. 据老夫多年行医经验来看, 汇编阶段不过是将汇编指令的机器码查找出翻译成机器码就可以了, 像查英汉字典一样有固定解释, 很少有出错的可能, 基本可诊断为问题出现在链接阶段, 而像地址分配, 内存对齐,重定位等都在这一阶段完成.
接下来用sizeof(fu_indicator_t)一看, 在ARM平台上竟然是4, 不是x86平台下的1了. 我试着改这个结构体里面各个位域的不同值发现, 各个位域的位置是随机的呀! 连顺序都会改变呢! 就是说这个结构体的位域的位置连顺序也不保证. 你见过一个结构体的比特序都会变化的吗? 当fu_indicator结构体里面的type位于后三个字节的时候当然就不是我预想的结果了.</p>

<p>解决办法: 强制这个结构体按最紧凑的方式对齐, 可以在声明fu_indicator结构体后加入&#8221;<strong>attribute</strong> ((packed))&#8221; 或在Makefile里的加编译选项&#8221;-fpack-struct&#8221;, 这样fu_indicator结构体的长度就为1字节了, 比特顺序也能得到保证. 或按最保险的方法: 放弃用位域这种结构, 而直接用按位操作来代替.</p>

<p>总结: 位域这种结构移植性是非常差的. C语言参考手册说了: 依赖于存储策略是危险的, 原因有几个. 1, 不同的计算机对数据类型的对齐限制不同. 2, 位字段宽度的限制不同. 3, 字节序不同. 甚至比特序也不同, 像上面的例子在arm平台就在同一个结构体上出现了截然相反的比特序. 如处于移植性考虑, 尽量不要用位域这种结构体来实现设置位的操作, 而是直接用按位操作.</p>

<p>另: 从这个<a href="http://www.linuxforum.net/forum/printthread.php?Cat=&amp;Board=embedded&amp;main=535759&amp;type=thread">帖子</a>来看, 这个问题还和GCC的版本有关.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2012/01/12/e98092e5bd92e4b8ade79a84e694b9e8bf9b/">递归中的改进</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2012-01-12T04:57:30+08:00" pubdate data-updated="true">Jan 12<span>th</span>, 2012</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>在<a href="http://hmgle.com/archives/204">上一篇</a>(<a href="http://hmgle.com/archives/204">一次面试</a>)中, 我用递归实现了输出所有可接受序列的排队方法. 后来, 我意识到, 在递归中, 频繁地申请内存来存储新增加的可接受序列的字符串, 再释放掉这片存储区域的方法是不必要的. 因为在递归中每调用一次新的递归后, 这时的可接受序列的字符串前面部分是一样的, 可以每次调用递归函数都用这块存储区域. 这时我们就不能用strcat()函数来加入新的字符了, 而是要先计算出目前要修改的字符的位置(pstr + (num_of_push_fiftycents * 2 - sum_of_fiftycents_inbox)), 然后直接在这个位置上修改要加入的字符. 改进后的代码如下:</p>

<pre><code>#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;string.h&gt;
#include &lt;errno.h&gt;

#define USEMALLOC   0

static unsigned int COUNT = 0;

static void
sale_ticket(int num_of_push_fiftycents, int sum_of_fiftycents_inbox, char *pstr, const int num_of_fiftycents)
{
    /*
     * 若钱箱内五角钱币为空, 且还有五毛游客排队时, 
     * 则下次只能接受五毛游客购票
     */
    if (sum_of_fiftycents_inbox == 0 &amp;&amp; num_of_push_fiftycents &lt; num_of_fiftycents) {
#if USEMALLOC
        strcat(pstr, "F");  /* 把"F"加到字符串尾部表示有五角进了售票员的钱箱 */
#else
        *(pstr + (num_of_push_fiftycents * 2 - sum_of_fiftycents_inbox)) = 'F';
#endif
        sale_ticket(num_of_push_fiftycents + 1, 1, pstr, num_of_fiftycents);
    }

    /*
     * 若钱箱内五毛钱币非空, 且还有五毛游客排队,
     * 则下次可以接受两种游客的购票请求
     */
    if (sum_of_fiftycents_inbox &gt; 0 &amp;&amp; num_of_push_fiftycents &lt; num_of_fiftycents) {
        /* 情况1: 下一张票卖给1元游客 */
#if USEMALLOC
        strcat(pstr, "T");  /* 把"T"加到字符串尾部表示有1元进了售票员的钱箱 */
#else
        *(pstr + (num_of_push_fiftycents * 2 - sum_of_fiftycents_inbox)) = 'T';
#endif
        sale_ticket(num_of_push_fiftycents, sum_of_fiftycents_inbox - 1, pstr, num_of_fiftycents);

        /* 情况2: 下一张票卖给五毛游客 */
#if USEMALLOC
        strcat(pstr, "F");
#else
        *(pstr + (num_of_push_fiftycents * 2 - sum_of_fiftycents_inbox)) = 'F';
#endif
        sale_ticket(num_of_push_fiftycents + 1, sum_of_fiftycents_inbox + 1, pstr, num_of_fiftycents);
    }

    /* 
     * 排队的只剩下手持一元的游客,
     * 下一张票只能卖给这类游客了
     */
    if (sum_of_fiftycents_inbox &gt; 0 &amp;&amp; num_of_push_fiftycents == num_of_fiftycents) {
#if USEMALLOC
        strcat(pstr, "T");
#else
        *(pstr + (num_of_push_fiftycents * 2 - sum_of_fiftycents_inbox)) = 'T';
#endif
        sale_ticket(num_of_push_fiftycents, sum_of_fiftycents_inbox - 1, pstr, num_of_fiftycents);
    }

    /*
     * 当所有游客都买到票了,
     * 则输出之前记录的买票顺序字符串
     */
    if (sum_of_fiftycents_inbox == 0 &amp;&amp; num_of_push_fiftycents &gt;= num_of_fiftycents) {
        COUNT++;
        printf("%s\n", pstr);
        return;
    }
}

int
main(int argc, char **argv)
{
    char *prt;
    int max_push;   /* 五毛游客数, 即五毛进钱箱的最大次数 */

    if (argc &lt; 2) {
        fprintf(stderr, "usage: %s num\n", argv[0]);
        exit(0);
    }
    max_push = atoi(argv[1]);
#if 0
    if (max_push &lt;= 0) {
        fprintf(stderr, "usage: %s num\n", argv[0]);
        exit(0);
    }
#endif
    if ((prt = malloc(2 * max_push + 1)) == NULL) {
        perror("main: malloc");
        exit(1);
    }
    memset(prt, 0, 2 * max_push + 1);

    sale_ticket(0, 0, prt, max_push);
    printf("The total number is: %d\n", COUNT);
    free(prt);

    return 0;
}
</code></pre>

<p>不过, 频繁的申请, 释放内存并不是这个程序的瓶颈. 修改后的程序运行时间基本是和原来一样的. 原因之一是每一次调用malloc申请到的其实是同一片区域, 没有调用到sbrk()申请过一片大的存储区域. 另一个原因是递归实在是效率低下, 没有留给别的东西当瓶颈的机会.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2011/12/26/e4b880e6aca1e99da2e8af95/">一次面试</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2011-12-26T15:19:52+08:00" pubdate data-updated="true">Dec 26<span>th</span>, 2011</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>上周六(12.24)去X公司面试, 打了趟酱油. 收获还是有的.</p>

<p>上午十点来到X公司. 先是笔试: 题目类型是Linux C++的, 120分钟. 题目还记得些.</p>

<p>前面几题是问答题: 1.Linux下malloc函数的实现. 只依稀记得 K&amp;R 里大概提了下. 2. errno的作用及实现. 实现我还真不知道怎么答. 3. sync命令的作用. 简单的说: 同步缓冲区数据到设备. 4. 好象是问TCP连接中如何确定send的数据被接收方全部接受完. 不知道是不是通过接收方对数据包进行对齐检校后再回应发送方而实现的. TCP是可靠连接嘛. 5. Linux中线程和进程的异同. 这个问题每一本讲Linux编程的书应该都有详细解释. 然后是几道编程题: 前面3题都是简单的字符串操作之类的, 没什么好说的. 看到第4题的时候觉得有点意思了:</p>

<pre><code>  某公园门票5角, 有5个游客手里有且仅有一张5角纸币,
  另外5个游客手里有且仅有一张1元纸币. 售票员手中
  没有任何纸币. 设计一个程序演示这10个游客可使售票员
  能顺利找零的所有排队方法.
  例如 "5 5 5 5 5 10 10 10 10 10" 这种方法就能顺利找零.
</code></pre>

<p>这题看起来眼熟了(后来回来才回忆起在Richard.A.Brualdi的那本组合数学里看的, 著名的Catalan数呀). 当时老是想去带吸收壁的随机行走问题去了, 其实就是同样问题的不同阐述而已, 不同阐述的Catalan问题还多着呢: 元素的进栈出栈具体有哪些方式, 列举n对括号的所有合法方式, 将凸多边形划分成三角形区域的方法等等, 举不胜举.
题目说演示, 那就把所有的可接受序列打印出来吧. 我想着想着就想到用递归实现, 不过当时根本没有划分清楚不同的状态: 比如售票员手中有几张5角的票, 还有几个五毛游客在排队等等. 因此没写明白. 回去捋了下, 果然用递归实现是很易理解的, 而且容易扩展: 比如<del>再加几种类型的纸币也可以很容易修改程序使之继续可用</del>(钱币类型多的话不是想象中的那么容易的). 不过缺点就是递归效率太低. 因为字符串 &#8220;10&#8221; 太长了, 所以就用 &#8220;T&#8221; 表示手持1元的游客购票, 用 &#8220;F&#8221; 表示持有5角的游客购票. 把 &#8220;F&#8221; 替换成 &#8220;(&#8220;, 把 &#8220;T&#8221; 替换成 &#8220;)&#8221; 就是列出所有合法的括号配对方法了. 代码如下:</p>

<pre><code>#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;string.h&gt;
#include &lt;errno.h&gt;

static unsigned int COUNT = 0;

void sale_ticket(int num_of_push_fiftycents, int sum_of_fiftycents_instack, char *pstr, const int max_push)
{
    /*
     * 若钱箱内五角钱币为空， 且还有持有五角的游客排队时，则下次
     * 只能接受五角游客购票。
     */
    if (sum_of_fiftycents_instack == 0 &amp;&amp; num_of_push_fiftycents &lt; max_push) {
        strcat(pstr, "F");      /* 把F加到字符串尾部表示有五角进了售票员的钱箱 */
        sale_ticket(num_of_push_fiftycents + 1, 1, pstr, max_push);
    }

    /*
     * 若钱箱内五角钱币非空， 且还有持有五角的游客排队时， 则下次
     * 可以接受两种游客的购票要求。
     */
    if (sum_of_fiftycents_instack &gt; 0 &amp;&amp; num_of_push_fiftycents &lt; max_push) {
        /* 情况1：下一个游客是1元党 */
        char *new_pstr;
        if ((new_pstr = malloc(2 * max_push + 1)) == NULL) {
            perror("sale_ticket: malloc");
            exit(1);
        }
        strcpy(new_pstr, pstr);
        strcat(new_pstr, "T");  /* 把T加到字符串尾部表示有五角出了钱箱， 即找零 */

        COUNT++;            /* 又多了一种可接受的排队方案 */
        sale_ticket(num_of_push_fiftycents, sum_of_fiftycents_instack - 1, new_pstr, max_push);

        /* 情况2：下一个购票的是五毛 */
        strcat(pstr, "F");
        sale_ticket(num_of_push_fiftycents + 1, sum_of_fiftycents_instack + 1, pstr, max_push);
    }

    /*
     * 当只剩下一元党在排队购票时，下一个购票的必然是一元的了
     */
    if (sum_of_fiftycents_instack &gt; 0 &amp;&amp; num_of_push_fiftycents == max_push) {
        strcat(pstr, "T");
        sale_ticket(num_of_push_fiftycents, sum_of_fiftycents_instack - 1, pstr, max_push);
    }

    /*
     * 当五毛入钱箱次数等于持有五毛游客的数量，
     * 且钱箱内五角钱币为空时， 表明到达了边界，
     * 则输出之前记录的买票顺序字符串. 并释放
     * 内存, 返回.
     */
    if (num_of_push_fiftycents == max_push &amp;&amp; sum_of_fiftycents_instack == 0) {
        printf("%s\n", pstr);
        free(pstr);
        return;
    }
}

int main(int argc, char **argv)
{
    char *prt;
    int max_push;   /* 五毛游客数, 即五毛进钱箱的最大次数 */

    if (argc &lt; 2) {
        fprintf(stderr, "usage: %s num\n", argv[0]);
        exit(0);
    }
    max_push = atoi(argv[1]);
    if (max_push &gt; 0)
        COUNT++;
    if ((prt = malloc(2 * max_push + 1)) == NULL) {
        perror("main: malloc");
        exit(1);
    }
    memset(prt, 0, 2 * max_push + 1);

    sale_ticket(0, 0, prt, max_push);
    printf("The total number is: %d\n", COUNT);
    return 0;
}
</code></pre>

<p>输入程序名后加数字即运行. 设置的数字不要超过16, 根据卡特兰数的一般项公式: Cn = (2*n)!/((n+1)! n!) . 第16项为35357670, 把所有可接受的排队顺序字符串输出需要1.1G的空间! 在我机器上大概10秒才运行完. 输入5的情况见这里:<a href="http://codepad.org/VKu9Bbb8">http://codepad.org/VKu9Bbb8</a></p>

<p>最后一题问的是如何排查一个程序的瓶颈. 很惭愧我不知道.</p>

<p>下午项目面试: 走进X公司的内部, 里面环境出乎我意料: 像个饭馆, 看上去挺惬意的, 不过里面没有人逗留. 最后面试官问了如何用多路复用改进我目前接触的项目(面试官技术不错, 听我稍微介绍完项目后就看出用定时轮询的方式耗资源).只要和网络开发有关的一般都会问到多路复用: select和poll机制. 这次果然也是. 结果没答明白. 拿了盒冬瓜茶就被叫回去了.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2011/12/11/e79c8be4ba86e8bf99e6a0b7e79a84makefile/">看了这样的makefile</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2011-12-11T04:23:18+08:00" pubdate data-updated="true">Dec 11<span>th</span>, 2011</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>GNU make是个非常好的工具. 大部分Linux程序员都自己编写Makefile, 再利用make构建工程. 优秀的程序员编写层次分明的代码, 将它们放在合适的位置, 优雅地用make生成目标文件以及管理工程. 不过, 再好的工具和材料, 到了笨拙建造师手里, 也有可能造出丑陋的建筑. 我就看了这样一个例子.</p>

<p>这个工程共有 3 层目录: 顶层有一个makefile. 要编译某个平台的目标文件首先要进入这个以这个平台名字命名的子目录, 比如 &#8220;Linux-x86-xx&#8221;. 子目录&#8221;Linux-x86-xx&#8221;内也有个makefile, 打开一看, 部分语句是这样的:</p>

<pre><code># makefile
compilevos: generateconfigfiles
        $(MAKE) -f ../../makefile xos.o
generateconfigfiles: runtailor
runtailor:
    ...
</code></pre>

<p>发现上两层目录已经不属于这个工程了. 又看了下readme才知道要编译目标得先运行这个&#8221;Linux-x86-xx&#8221;目录里面的一个脚本&#8221;makelib&#8221;, 部分语句是这样的:</p>

<pre><code># makelib
cd obj
make -f ../makefile compilelibs
cd ..
</code></pre>

<p>先进入&#8221;obj&#8221;这个子目录, 这样&#8221;makefile&#8221; 里面的&#8221;$(MAKE) -f ../../makefile xos.o&#8221; 其实是调用上层目录的makefile了. 看得我都吐血了. 往下看发现依然现象严重, 写这个makefile的哥儿们竟全用名字诸如&#8221;makeobj&#8221;, &#8220;makexox&#8221;, &#8220;maketarget&#8221;等脚本调用make的, 关键是在脚本里每次调用之前都先cd到另外一个目录里, 在makefile根本不知道这条命令是在哪个目录里执行的. &#8220;goto&#8221;都不能比肩.</p>

<p>这么好的make就这样给糟蹋了.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2011/10/18/e5b58ce585a5e5bc8flinuxe59fbae4ba8eframebuffere79a84jpege6a0bce5bc8fe69cace59cb0lcde5b18fe698bee7a4ba/">嵌入式Linux基于framebuffer的jpeg格式本地LCD屏显示</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2011-10-18T07:20:31+08:00" pubdate data-updated="true">Oct 18<span>th</span>, 2011</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>在基于Linux的视频监控采集系统中,摄像头采集到的一帧视频图像数据一般都是经过硬件自动压缩成jpeg格式的,然后再保存到摄像头设备的缓冲区.如果要把采集到的jpeg格式显示在本地LCD屏上,由于我们的Linux系统没有移植任何GUI系统,就要考虑以下方面:
1. 将jpeg格式解压缩为位图格式,也就是jpeg解码.</p>

<ol>
<li><p>将解码出来的位图格式输出到本地的LCD屏上. 在Linux系统下是通过写入帧缓冲(framebuffer)来实现的.</p></li>
<li><p>framebuffer相当于为LCD设备提供一个统一的接口,对framebuffer的操控会反映到LCD显示设备上去. 如果配置Linux内核时没有找到支持本地lcd屏这种型号的驱动,那我们要自己写lcd屏驱动,然后选择静态加入内核或以模块的形式加入内核动态加载.</p></li>
</ol>


<p>针对以上三点,我们逐一解决:</p>

<h2>1. jpeg解码</h2>

<p>先了解一下jpeg标准的编码过程:原始的一帧未压缩过的图像可以看成是RGB(红绿蓝)色彩空间上的一组向量集合,但在RGB空间是不利于数据压缩的,因此为了压缩先要把图像映射到利于压缩的YUV空间上(原因是因为人类的眼睛对于亮度差异的敏感度高于色彩变化,而YUV空间的一个基向量Y就是亮度), 这一步叫色彩空间转换.下一步可以在YUV空间上减少U(色调)和V(饱和度)的成分,也就是在亮度信息不减少的情况下移除部分色彩信息,谁叫人的眼睛对亮度的敏感优于对色彩的敏感呢.这一步叫缩减取样.下一步是将图像从色彩空间映射到频率空间,可以采用的变换方法有:离散余弦变换, 傅氏变换, 正弦变换等. 其中应用最广的是离散余弦变换(DCT).这一步是无损的,目的是为了在下一步称之为量化的过程中可以经过四舍五入删除高频量得到压缩后的矩阵.量化之后就是对这个矩阵的编码问题了.针对这个矩阵的分布特点, 采用&#8221;Z&#8221;字形的顺序扫描编排,然后进行RLE行程编码, 把大量连续重复的数据压缩.最后再用范式Huffman编码.要了解详细的过程,可以查看<a href="http://www.jpeg.org/">JPEG标准</a>.</p>

<p>而解码就是以上编码的逆过程了.除非想要自己实现jpeg的编码和解码函数,我们可以不必细究这些过程,而是直接使用别人已经实现的jpeg编码解码库.在Linux平台下, 有libjpeg库, 它是完全用C语言编写的, 依照它的许可协议,可自由使用, 不是GPL协议,它可以用于商业目的.</p>

<p>libjpeg的6b版本有个问题,就是解码接口,它只接受文件源.打开源的函数<code>jpeg_stdio_src(j_decompress_ptr cinfo, FILE *infile)</code>要求解码源infile是文件.而我们希望解码的是直接来自映射内存中的数据.要解码内存流的话就要修改libjpeg的源码了,可以参考这里:<a href="http://my.unix-center.net/~Simon_fu/?p=565">http://my.unix-center.net/~Simon_fu/?p=565</a> 目前libjpeg的最新版8c已经解决了这个接口不好的问题了,它增加了对内存流解码的支持.通过调用函数</p>

<pre><code>jpeg_mem_src(&amp;cinfo, fdmem, st.st_size);
</code></pre>

<p>就可以将保存在内存的jpeg格式数据作为源输入了.因此我们就用libjpeg 8c这个版本来解码.</p>

<p>用到的函数主要有:</p>

<ol>
<li><p>初始化jpeg解压对象:</p>

<p> /<em> init jpeg decompress object error handler </em>/
 cinfo.err = jpeg_std_error(&amp;jerr);
 jpeg_create_decompress(&amp;cinfo);</p></li>
<li><p>绑定jpeg解压对象到输入流:</p>

<p>   /<em> bind jpeg decompress object to infile </em>/</p>

<h1>if READ_FILE   // 从jpeg文件读入</h1>

   jpeg_stdio_src(&amp;cinfo, infile);

<h1>elif READ_MEM  // 从内存读入jpeg格式</h1>

   jpeg_mem_src(&amp;cinfo, fdmem, st.st_size);

<h1>endif</h1></li>
<li><p>读取jpeg头部信息:</p>

<p>   /<em> read jpeg header </em>/
   jpeg_read_header(&amp;cinfo, TRUE);</p></li>
<li><p>解压过程:</p>

<p>   /<em> decompress process </em>/
   jpeg_start_decompress(&amp;cinfo);</p></li>
</ol>


<p>调用这个函数之后,可以得到jpeg图像的下面几个参数:</p>

<ol>
<li><p>output_width // 图像的宽度</p></li>
<li><p>output_height // 图像的高度</p></li>
<li><p>output_components // 每个像素占用的字节数</p></li>
</ol>


<p>我们采用每扫描一行像素就输出到屏幕的方法的话,根据以上参数可以确定分配一行信息需要的缓冲区:</p>

<pre><code>    buffer = (unsigned char *)malloc(cinfo.output_width *
            cinfo.output_components);
</code></pre>

<p>总共需要扫描output_height行.</p>

<ol>
<li><p>读取一行扫描数据并输出到LCD屏幕:</p>

<p>   y = 0;
   while (cinfo.output_scanline &lt; cinfo.output_height) {</p>

<pre><code>   jpeg_read_scanlines(&amp;cinfo, &amp;buffer, 1);
   if (fb_depth == 16) {   // 如果显示设备色深是16位
       ...
   } else if (fb_depth == 24) {    // 如果显示设备色深是24位
       ...
   } else if (fb_depth == 32) {    // 如果显示设备色深是32位
       ...
   }
   y++;
</code></pre>

<p>   }</p></li>
<li><p>结束jpeg解码:</p>

<p>   /<em> finish decompress, destroy decompress object </em>/
   jpeg_finish_decompress(&amp;cinfo);
   jpeg_destroy_decompress(&amp;cinfo);</p></li>
<li><p>释放缓冲区:</p>

<p>   /<em> release memory buffer </em>/
   free(buffer);</p></li>
</ol>


<h2>2. 输出位图到LCD屏</h2>

<p>通过framebuffer直接写屏的主要步骤有:</p>

<ol>
<li><p>打开framebuffer设备:</p>

<p>   /<em> open framebuffer device </em>/
   fbdev = fb_open(&#8220;/dev/fb0&#8221;);</p></li>
<li><p>获取framebuffer设备参数:</p>

<p>   /<em> get status of framebuffer device </em>/
   fb_stat(fbdev, &amp;fb_width, &amp;fb_height, &amp;fb_depth);</p></li>
<li><p>映射framebuffer设备到共享内存:</p>

<p>   screensize = fb_width * fb_height * fb_depth / 8;
   fbmem = fb_mmap(fbdev, screensize);</p></li>
<li><p>直接对映射到那片内存进行写操作,LCD屏刷新刷新时就会反应到屏幕上去了.</p>

<p>   y = 0;
   while (cinfo.output_scanline &lt; cinfo.output_height) {</p>

<pre><code>   jpeg_read_scanlines(&amp;cinfo, &amp;buffer, 1);
   if (fb_depth == 16) {
       unsigned short color;

       for (x = 0; x &lt; cinfo.output_width; x++) {
           color =
               RGB888toRGB565(buffer[x * 3],
                       buffer[x * 3 + 1], buffer[x * 3 + 2]);
           fb_pixel(fbmem, fb_width, fb_height, x, y, color);
       }
   } else if (fb_depth == 24) {
       memcpy((unsigned char *) fbmem + y * fb_width * 3,
               buffer, cinfo.output_width * cinfo.output_components);
   } else if (fb_depth == 32) {
       // memcpy((unsigned char *) fbmem + y * fb_width * 4,
               // buffer, cinfo.output_width * cinfo.output_components);
       for (x = 0; x &lt; cinfo.output_width; x++) {
           *(fbmem + y * fb_width * 4 + x * 4)     = (unsigned char) buffer[x * 3 + 2];
           *(fbmem + y * fb_width * 4 + x * 4 + 1) = (unsigned char) buffer[x * 3 + 1];
           *(fbmem + y * fb_width * 4 + x * 4 + 2) = (unsigned char) buffer[x * 3 + 0];
           *(fbmem + y * fb_width * 4 + x * 4 + 3) = (unsigned char) 0;
       }
   }
   y++;    // next scanline
</code></pre>

<p>   }</p></li>
<li><p>卸载映射framebuffer的那部分内存:</p>

<p>   /<em> unmap framebuffer&#8217;s shared memory </em>/
   fb_munmap(fbmem, screensize);</p></li>
<li><p>关闭framebuffer设备:</p>

<p>   close(fbdev);</p></li>
</ol>


<p>根据以上两点,可以写一个测试程序,在不开X-window图形系统的情况下,将本地的jpeg文件直接显示到屏幕上.</p>

<pre><code>#include    &lt;stdio.h&gt;
#include    &lt;string.h&gt;
#include    &lt;stdlib.h&gt;
#include    &lt;unistd.h&gt;
#include    &lt;sys/ioctl.h&gt;
#include    &lt;sys/types.h&gt;
#include    &lt;sys/stat.h&gt;
#include    &lt;errno.h&gt;
#include    &lt;fcntl.h&gt;
#include    &lt;sys/mman.h&gt;
#include    &lt;linux/fb.h&gt;
#include    "jpeglib.h"
#include    "jerror.h"

#define FB_DEV  "/dev/fb0"
#define __fnc__ __FUNCTION__

#define debug           0
#define debug_printf    0
#define BYREAD          0
#define BYMEM           1

/* function deciaration */

void usage(char *msg);
unsigned short RGB888toRGB565(unsigned char red,
        unsigned char green, unsigned char blue);
int fb_open(char *fb_device);
int fb_close(int fd);
int fb_stat(int fd, unsigned int *width, unsigned int *height, unsigned int *    depth);
void *fb_mmap(int fd, unsigned int screensize);
void *fd_mmap(int fd, unsigned int filesize);
int fb_munmap(void *start, size_t length);
int fb_pixel(void *fbmem, int width, int height,
        int x, int y, unsigned short color);

#if(debug)
void draw(unsigned char *fbp,
        struct fb_var_screeninfo vinfo,
        struct fb_fix_screeninfo finfo);
#endif

/* function implementation */

int main(int argc, char **argv)
{
    struct jpeg_decompress_struct cinfo;
    struct jpeg_error_mgr jerr;
#if(BYREAD)
    FILE *infile;
#endif
    int fd;
    unsigned char *buffer;
    struct stat st;

    int fbdev;
    char *fb_device;
    unsigned char *fbmem;
    unsigned char *fdmem;
    unsigned int screensize;
    unsigned int fb_width;
    unsigned int fb_height;
    unsigned int fb_depth;
    register unsigned int x;
    register unsigned int y;

    /* check auguments */
    if (argc != 2) {
        usage("insuffient auguments");
        exit(-1);
    }

    /* open framebuffer device */
    if ((fb_device = getenv("FRAMEBUFFER")) == NULL)
        fb_device = FB_DEV;
    fbdev = fb_open(fb_device);

    /* get status of framebuffer device */
    fb_stat(fbdev, &amp;fb_width, &amp;fb_height, &amp;fb_depth);

    /* map framebuffer device to shared memory */
    screensize = fb_width * fb_height * fb_depth / 8;
    fbmem = fb_mmap(fbdev, screensize);

#if (BYREAD)
    /* open input jpeg file */
    if ((infile = fopen(argv[1], "rb")) == NULL) {
        fprintf(stderr, "open %s failed\n", argv[1]);
        exit(-1);
    }
#endif

    if ((fd = open(argv[1], O_RDONLY)) &lt; 0) {
        perror("open");
        exit(-1);
    }

    if (fstat(fd, &amp;st) &lt; 0) {
        perror("fstat");
        exit(-1);
    }

    fdmem = fd_mmap(fd, st.st_size);

    /* init jpeg decompress object error handler */
    cinfo.err = jpeg_std_error(&amp;jerr);
    jpeg_create_decompress(&amp;cinfo);

    /* bind jpeg decompress object to infile */
#if (BYREAD)
    jpeg_stdio_src(&amp;cinfo, infile);
#endif

#if (BYMEM)
    jpeg_mem_src(&amp;cinfo, fdmem, st.st_size);
#endif

    /* read jpeg header */
    jpeg_read_header(&amp;cinfo, TRUE);

    /* decompress process */
    jpeg_start_decompress(&amp;cinfo);
    if ((cinfo.output_width &gt; fb_width) ||
            (cinfo.output_height &gt; fb_height)) {
        printf("too large jpeg file, can't display\n");
#if (0)
        return -1;
#endif
    }

    buffer = (unsigned char *) malloc(cinfo.output_width *
            cinfo.output_components);

    struct fb_fix_screeninfo fb_finfo;
    struct fb_var_screeninfo fb_vinfo;

    if (ioctl(fbdev, FBIOGET_FSCREENINFO, &amp;fb_finfo)) {
        perror(__fnc__);
        return -1;
    }

    if (ioctl(fbdev, FBIOGET_VSCREENINFO, &amp;fb_vinfo)) {
        perror(__fnc__);
        return -1;
    }

#if(debug)
    draw(fbmem, fb_vinfo, fb_finfo);
#endif
    y = 0;
    while (cinfo.output_scanline &lt; cinfo.output_height) {
        jpeg_read_scanlines(&amp;cinfo, &amp;buffer, 1);
        if (fb_depth == 16) {
            unsigned short color;

            for (x = 0; x &lt; cinfo.output_width; x++) {
                color =
                    RGB888toRGB565(buffer[x * 3],
                            buffer[x * 3 + 1], buffer[x * 3 + 2]);
                fb_pixel(fbmem, fb_width, fb_height, x, y, color);
            }
        } else if (fb_depth == 24) {
            memcpy((unsigned char *) fbmem + y * fb_width * 3,
                    buffer, cinfo.output_width * cinfo.output_components);
        } else if (fb_depth == 32) {
            // memcpy((unsigned char *) fbmem + y * fb_width * 4,
                    // buffer, cinfo.output_width * cinfo.output_components);
            for (x = 0; x &lt; cinfo.output_width; x++) {
                * (fbmem + y * fb_width * 4 + x * 4)     = (unsigned char)       buffer[x * 3 + 2];
                * (fbmem + y * fb_width * 4 + x * 4 + 1) = (unsigned char)       buffer[x * 3 + 1];
                * (fbmem + y * fb_width * 4 + x * 4 + 2) = (unsigned char)       buffer[x * 3 + 0];
                * (fbmem + y * fb_width * 4 + x * 4 + 3) = (unsigned char) 0;
            }
        }
        y++;    // next scanline
    }

    /* finish decompress, destroy decompress object */
    jpeg_finish_decompress(&amp;cinfo);
    jpeg_destroy_decompress(&amp;cinfo);

    /* release memory buffer */
    free(buffer);

#if (BYREAD)
    /* close jpeg inputing file */
    fclose(infile);
#endif

    /* unmap framebuffer's shared memory */
    fb_munmap(fbmem, screensize);

#if (BYMEM)
    munmap(fdmem, (size_t) st.st_size);
    close(fd);
#endif

    /* close framebuffer device */
    fb_close(fbdev);

    return 0;
}

void usage(char *msg)
{
    fprintf(stderr, "%s\n", msg);
    printf("Usage: fv some-jpeg-file.jpg\n");
}

/* open framebuffer device.
 * return positive file descriptor if success,
 * else return -1
 */
int fb_open(char *fb_device)
{
    int fd;

    if ((fd = open(fb_device, O_RDWR)) &lt; 0) {
        perror(__fnc__);
        return -1;
    }
    return fd;
}

int fb_close(int fd)
{
    return (close(fd));
}

/* get framebuffer's width, height, and depth.
 * return 0 if success, else return -1.
 */
int fb_stat(int fd, unsigned int *width, unsigned int *height, unsigned int *    depth)
{
    struct fb_fix_screeninfo fb_finfo;
    struct fb_var_screeninfo fb_vinfo;

    if (ioctl(fd, FBIOGET_FSCREENINFO, &amp;fb_finfo)) {
        perror(__fnc__);
        return -1;
    }

    if (ioctl(fd, FBIOGET_VSCREENINFO, &amp;fb_vinfo)) {
        perror(__fnc__);
        return -1;
    }

    *width = fb_vinfo.xres;
    *height = fb_vinfo.yres;
    *depth = fb_vinfo.bits_per_pixel;

    return 0;
}

/* map shared memory to framebuffer device.
 * return maped memory if success
 * else return -1, as mmap dose
 */
void *fb_mmap(int fd, unsigned int screensize)
{
    caddr_t fbmem;

    if ((fbmem = mmap(0, screensize, PROT_READ | PROT_WRITE,
                    MAP_SHARED, fd, 0)) == MAP_FAILED) {
        perror(__func__);
        return (void *) (-1);
    }

    return fbmem;
}

/* map shared memmory to a opened file */
void *fd_mmap(int fd, unsigned int filesize)
{
    caddr_t fdmem;

    if ((fdmem = mmap(0, filesize, PROT_READ,
                    MAP_SHARED, fd, 0)) == MAP_FAILED) {
        perror(__func__);
        return (void *) (-1);
    }

    return fdmem;
}

/* unmap map memory for framebuffer device */
int fb_munmap(void *start, size_t length)
{
    return (munmap(start, length));
}

/* convert 24bit RGB888 to 16bit RGB565 color format */
unsigned short RGB888toRGB565(unsigned char red,
        unsigned char green, unsigned char blue)
{
    unsigned short B = (blue &gt;&gt; 3) &amp; 0x001F;
    unsigned short G = ((green &gt;&gt; 2) &lt;&lt; 5) &amp; 0x07E0;
    unsigned short R = ((red &gt;&gt; 3) &lt;&lt; 11) &amp; 0xF800;

    return (unsigned short) (R | G | B);
}

/* display a pixel on the framebuffer device.
 * fbmem is the starting memory of framebuffer,
 * width and height are dimension of framebuffer,
 * width and height are dimension of framebuffer,
 * x and y are the coordinates to display,
 * color is the pixel's color value.
 * return 0 if success, otherwise return -1.
 */
int fb_pixel(void *fbmem, int width, int height,
        int x, int y, unsigned short color)
{
    if ((x &gt; width) || (y &gt; height))
        return -1;

    unsigned short *dst = ((unsigned short *) fbmem + y * width + x);

    *dst = color;
    return 0;
}
</code></pre>

<h2>3. LCD驱动</h2>

<p>我们用到的是一块东华3.5寸数字屏,型号为WXCAT35-TG3.下面的驱动程序是韦东山老师课堂上现场写的,如下:</p>

<pre><code>#include &lt;linux/module.h&gt;
#include &lt;linux/kernel.h&gt;
#include &lt;linux/errno.h&gt;
#include &lt;linux/string.h&gt;
#include &lt;linux/mm.h&gt;
#include &lt;linux/slab.h&gt;
#include &lt;linux/delay.h&gt;
#include &lt;linux/interrupt.h&gt;
#include &lt;linux/fb.h&gt;
#include &lt;linux/init.h&gt;
#include &lt;linux/ioport.h&gt;
#include &lt;linux/dma-mapping.h&gt;

#include &lt;asm/uaccess.h&gt;
#include &lt;asm/system.h&gt;
#include &lt;asm/irq.h&gt;
#include &lt;asm/setup.h&gt;

/* WXCAT35-TG3 */
struct s3c_lcd_regs {
    unsigned long   lcdcon1;
    unsigned long   lcdcon2;
    unsigned long   lcdcon3;
    unsigned long   lcdcon4;
    unsigned long   lcdcon5;
    unsigned long   lcdsaddr1;
    unsigned long   lcdsaddr2;
    unsigned long   lcdsaddr3;
    unsigned long   redlut;
    unsigned long   greenlut;
    unsigned long   bluelut;
    unsigned long   reserved[9];
    unsigned long   dithmode;
    unsigned long   tpal;
    unsigned long   lcdintpnd;
    unsigned long   lcdsrcpnd;
    unsigned long   lcdintmsk;
    unsigned long   lpcsel;
};

static u32 colregs[16];
static struct fb_info *s3c_fb_info;
static dma_addr_t s3c_fb_handle;
static unsigned long fb_va;

/* from pxafb.c */
static inline unsigned int chan_to_field(unsigned int chan, struct fb_bitfield *bf)
{
    chan &amp;= 0xffff;
    chan &gt;&gt;= 16 - bf-&gt;length;
    return chan &lt;&lt; bf-&gt;offset;
}

static int s3cfb_setcolreg(unsigned regno,
                   unsigned red, unsigned green, unsigned blue,
                   unsigned transp, struct fb_info *info)
{
    unsigned int val;

    /* dprintk("setcol: regno=%d, rgb=%d,%d,%d\n", regno, red, green, blue); */

    /* true-colour, use pseuo-palette */

    if (regno &lt; 16) {
        u32 *pal = s3c_fb_info-&gt;pseudo_palette;

        val  = chan_to_field(red,   &amp;s3c_fb_info-&gt;var.red);
        val |= chan_to_field(green, &amp;s3c_fb_info-&gt;var.green);
        val |= chan_to_field(blue,  &amp;s3c_fb_info-&gt;var.blue);

        pal[regno] = val;
    }

    return 0;
}

static struct fb_ops s3cfb_ops = {
    .owner      = THIS_MODULE,
//  .fb_check_var   = clps7111fb_check_var,
//  .fb_set_par = clps7111fb_set_par,
//  .fb_setcolreg   = clps7111fb_setcolreg,
//  .fb_blank   = clps7111fb_blank,

    .fb_setcolreg   = s3cfb_setcolreg,
    .fb_fillrect    = cfb_fillrect,
    .fb_copyarea    = cfb_copyarea,
    .fb_imageblit   = cfb_imageblit,
};

struct s3c_lcd_regs *s3c_lcd_regs;
static volatile unsigned long *gpccon;
static volatile unsigned long *gpdcon;
static volatile unsigned long *gpgcon;

int s3c_lcd_init(void)
{
    extern int debug_lcd;
    /* 1. 分配一个fb_info结构体 */
    s3c_fb_info = framebuffer_alloc(0, NULL);
    printk("%s %d\n", __FUNCTION__, __LINE__);

    /* 2. 设置fb_info结构体 */
    /*
       2.1 设置固定的信息
       2.2 设置可变的信息
       2.3 设置操作函数
    */

    /* 24BPP(bits per pixel), 会用到4字节, 其中浪费1字节 */
    strcpy(s3c_fb_info-&gt;fix.id, "WXCAT35-TG3");
    // s3c_fb_info-&gt;fix.smem_start // frame buffer's physical address
    s3c_fb_info-&gt;fix.smem_len    = 320*240*32/8;
    s3c_fb_info-&gt;fix.type        = FB_TYPE_PACKED_PIXELS;
    s3c_fb_info-&gt;fix.visual      = FB_VISUAL_TRUECOLOR;
    s3c_fb_info-&gt;fix.line_length = 320 * 4;

    s3c_fb_info-&gt;var.xres             = 320;
    s3c_fb_info-&gt;var.yres             = 240;
    s3c_fb_info-&gt;var.xres_virtual     = 320;
    s3c_fb_info-&gt;var.yres_virtual     = 240;
    s3c_fb_info-&gt;var.bits_per_pixel   = 32;

    s3c_fb_info-&gt;var.red.offset       = 16;
    s3c_fb_info-&gt;var.red.length       = 8;

    s3c_fb_info-&gt;var.green.offset     = 8;
    s3c_fb_info-&gt;var.green.length     = 8;

    s3c_fb_info-&gt;var.blue.offset      = 0;
    s3c_fb_info-&gt;var.blue.length      = 8;

    //s3c_fb_info-&gt;var.activate         = FB_ACTIVATE;

    s3c_fb_info-&gt;fbops                = &amp;s3cfb_ops;
    s3c_fb_info-&gt;pseudo_palette       = colregs;

    /* 3. 硬件相关的操作 */
    /* 配置GPIO */
    gpccon     = ioremap(0x56000020, 4);
    gpdcon     = ioremap(0x56000030, 4);
    gpgcon     = ioremap(0x56000060, 4);
    *gpccon = 0xaaaaaaaa;
    *gpdcon = 0xaaaaaaaa;
    *gpgcon |= (3&lt;&lt;8);  /* GPG4 use as lcd_pwren */
    printk("%s %d\n", __FUNCTION__, __LINE__);

    s3c_lcd_regs = ioremap(0X4D000000, sizeof(struct s3c_lcd_regs));

    /*
     * VCLK = HCLK / [(CLKVAL+1)x2] = 100M/[(CLKVAL+1)x2] = 6.4
     * CLKVAL = 6.8 = 7
     * TFT LCD panel
     * 24bpp
     */
    s3c_lcd_regs-&gt;lcdcon1 = (7&lt;&lt;8)|(0&lt;&lt;7)|(3&lt;&lt;5)|(0x0d&lt;&lt;1)|(0&lt;&lt;0);
    printk("%s %d\n", __FUNCTION__, __LINE__);

    /* VBPD: 电子枪收到VSYNC信号后,"多长时间"才能跳回第1行
     * VBPD=14,      LCD: tvb=15
     * LINEVAL=239,  LCD: 有240行
     * VFPD=11,      LCD: tvf=12  // 发出最后一行数据后,再过多长时间才发出VSYNC
     * VSPW=2,       LCD: tvp=3   // VSYNC的宽度
     */
    s3c_lcd_regs-&gt;lcdcon2 = (14&lt;&lt;24)|(239&lt;&lt;14)|(11&lt;&lt;6)|(2&lt;&lt;0);

    /* HBPD: 电子枪收到HSYNC信号后,"多长时间"才能跳回第1列
     * HBPD=37,      LCD: thb=38
     * HORVAL=319,   LCD: 有320行
     * HFPD=19,      LCD: thf=20  // 发出最后一象素数据后,再过多长时间才发出HSYNC
     * HSPW=29,      LCD: thp=30   // VSYNC的宽度
     */
    s3c_lcd_regs-&gt;lcdcon3 = (37&lt;&lt;19)|(319&lt;&lt;8)|(19&lt;&lt;0);
    s3c_lcd_regs-&gt;lcdcon4 = 29;

    /* bit10:  在VCLK上升沿取数据 
     * bit9 :  VSYNC低电平有效
     * bit8 :  HSYNC低电平有效
     * bit5 :  PWREN低电平有效
     */ 
    s3c_lcd_regs-&gt;lcdcon5 = (1&lt;&lt;10)|(1&lt;&lt;9)|(1&lt;&lt;8)|(1&lt;&lt;5)|(0&lt;&lt;3);

    /* 分配frame buffer */
    fb_va = (unsigned long)dma_alloc_writecombine(NULL, s3c_fb_info-&gt;fix.smem_len, &amp;s3c_fb_handle, GFP_KERNEL);

    printk("fb_va = 0x%x, pa = 0x%x\n", fb_va, s3c_fb_handle);
    s3c_fb_info-&gt;fix.smem_start = s3c_fb_handle;
    s3c_fb_info-&gt;screen_base    = fb_va;

    /* 把framebuffer的地址告诉LCD控制器 */
    s3c_lcd_regs-&gt;lcdsaddr1 = (s3c_fb_info-&gt;fix.smem_start &gt;&gt; 1);
    s3c_lcd_regs-&gt;lcdsaddr2 = ((s3c_fb_info-&gt;fix.smem_start+320*240*4) &gt;&gt; 1) &amp; 0x1fffff;
    s3c_lcd_regs-&gt;lcdsaddr3 = 320*4/2;

    /* 使能LCD */
    s3c_lcd_regs-&gt;lcdcon1 |= (1&lt;&lt;0);

    /* 4. register_framebuffer */
    printk("%s %d\n", __FUNCTION__, __LINE__);
    //debug_lcd = 1;
    register_framebuffer(s3c_fb_info);
    printk("%s %d\n", __FUNCTION__, __LINE__);

    return 0; 
}

void s3c_lcd_exit(void)
{
    unregister_framebuffer(s3c_fb_info);
    dma_free_writecombine(NULL, s3c_fb_info-&gt;fix.smem_len, fb_va, s3c_fb_handle);
    iounmap(s3c_lcd_regs);
    iounmap(gpccon);
    iounmap(gpdcon);
    iounmap(gpgcon);
    framebuffer_release(s3c_fb_info);
}

module_init(s3c_lcd_init);
module_exit(s3c_lcd_exit);

MODULE_LICENSE("GPL");
</code></pre>

<p>然后把它加入到内核,以静态加载的模式启动.</p>

<p>最后,可以把读取内存jpeg格式数据输出到LCD屏的这部分整合到mjpg-stream或servfox去,就实现了采集图像本地显示了.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2011/09/11/servfoxe58886e69e90/">Servfox分析</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2011-09-11T13:57:20+08:00" pubdate data-updated="true">Sep 11<span>th</span>, 2011</time>
        
      </p>
    
  </header>


  <div class="entry-content"><h1><a href="http://hmgle.com/wiki/servfox_ans.html">servfox分析</a></h1>

<p>&#8211;by:hmgle Copyleft: <a href="http://creativecommons.org/licenses/by-nc-sa/3.0/deed.zh">CC BY-NC-SA</a></p>

<p>构建嵌入式Linux网络视频监控系统中,我们采用servfox来做服务器采集程序. servfox涉及到的内容主要有:V4L1接口、套接字和多线程编程. 这里简单分析一下servfox-R1_1_3.</p>

<h2>1. servfox做了什么?</h2>

<p>servfox在采集图像的过程中主要做什么事情?
它初始化摄像头设备后创建了线程1采集视频图像. 然后主程序创建一个套接字监听,阻塞等待客户端的请求连接. 连接成功后再创建线程2发送采集到的图像数据给客户端.</p>

<ul>
<li><p>线程1:采集视频图像.</p></li>
<li><p>线程2:发送图像数据给客户端.</p></li>
</ul>


<p>在采集线程和发送线程同时运行的情况下,会存在对存储压缩过的图像数据的缓冲区这个临界区竞争的情况. 为了能把采集到的一帧图像数据完整地发送出去,需要采用一些同步机制.
servfox只是个应用程序,它初始化设备,获取设备属性和图像属性,设置图像参数,捕捉图像数据,都是通过Video4Linux接口标准调用驱动的相关函数完成的. 本文末尾将会列举部分摄像头设备驱动要实现的file_oerations结构体里面的函数.</p>

<h2>2. servfox运行步骤</h2>

<p>servfox运行流程图如下:</p>

<p><img src="http://hmgle.com/photo_html/servfox_ans_.png" alt="" /></p>

<h3>2.1 从命令行传递参数给变量</h3>

<p>main()函数内,首先执行的是一个for循环体. 看一下里面的几个语句:</p>

<pre><code>...
if (strcmp (argv[i], "-d") == 0) {
    if (i + 1 &gt;= argc) {
        if(debug)
            printf ("No parameter specified with -d, aborting.\n");
        exit (1);
    }
    videodevice = strdup (argv[i + 1]);
}
...
</code></pre>

<p>videodevice保存了摄像头设备节点名称. 用户不指定的话,后面会将它设置为&#8221;/dev/video0&#8221;.</p>

<pre><code>...
if (strcmp (argv[i], "-g") == 0) {
    /* Ask for read instead default  mmap */
    grabmethod = 0;
}
...
</code></pre>

<p>通过grabmethod的设置就指定了采集图像时使用mmap()内存映射的方法还是read()读取的方法. 采用read系统调用来读取图像数据的话在连续抓取的情况下会发生频繁的用户态和内核态的切换,效率低. 通过mmap内存映射的话,把摄像头对应的设备文件映射到进程内存中,减少I/O操作,提高了效率. 因此启动servfox时不加&#8221;-g&#8221;选项的话默认采用grabmethod=1为mmap方式.</p>

<p>在for循环体里面还根据用户输入的选项分配了存储分辨率大小width/height,创建套接字时用的端口号serverport(默认为7070).</p>

<h3>2.2 初始化视频采集设备</h3>

<p>接下来主要要执行的语句有:</p>

<pre><code>memset (&amp;videoIn, 0, sizeof (struct vdIn)); // 将结构体videoIn初始化为0
</code></pre>

<p>先来看看videoIn这个结构体:</p>

<ul>
<li><p>vdIn 结构体(在spcav4l.h中定义,它里面的成员都是依据Video4Linux接口标准而定义的):</p>

<p>struct vdIn {</p>

<pre><code>int fd;             // 设备文件描述符
char *videodevice ;     // 设备,视频捕捉接口文件
struct video_mmap vmmap;
/* 用于内存映射方法时进行图像数据的获取,
 * 里面的成员.frame表示当前将获取的帧号,
 * 成员.height和.width表示图像高度和宽度,
 * 成员.format表示图像格式.
 */

struct video_capability videocap;
/* 包含设备的基本信息(设备名称,支持的最大最小分辨率,信号源信息等)
 */

int mmapsize;
struct video_mbuf videombuf;
/* 利用mmap映射到摄像头存储缓冲区的帧信息,
 * 包括帧的大小(size),最多支持的帧数(frames),
 * 每帧相对基址的偏移(offset)
 */

struct video_picture videopict;     // 采集到的图像的各种属性
struct video_window videowin;       // 包含capture area的信息
struct video_channel videochan;     // 各个信号源的属性
struct video_param videoparam;
int cameratype ;        // 是否能capture,彩色还是黑白,是否能裁剪等等
char *cameraname;       // 设备名称
char bridge[9];
int sizenative;         // available size in jpeg.
int sizeothers;         // others palette.
int palette;            // available palette.
int norme ;             // set spca506 usb video grabber.
int channel ;       // set spca506 usb video grabber 信号源个数
int grabMethod ;
unsigned char *pFramebuffer;    // 指向内存映射的指针
unsigned char *ptframe[4];      // 指向压缩后的帧的指针数组
int framelock[4];
pthread_mutex_t grabmutex;      // 视频采集线程和传输线程的互斥信号
int framesizeIn ;               // 视频帧的大小
volatile int frame_cour;        // 指向压缩后的帧的指针数组下标
int bppIn;      // 采集的视频帧的BPP
int hdrwidth;           // 采集的视频帧的宽度
int hdrheight;          // 采集的视频帧的高度
int formatIn;           // 采集的视频帧的格式
int signalquit;     // 停止视频采集的信号
</code></pre>

<p>};</p></li>
</ul>


<p>接下来执行:</p>

<pre><code>if (init_videoIn
            (&amp;videoIn, videodevice, width, height, format,grabmethod) != 0)
</code></pre>

<p>这个函数主要是设置了grabmethod:用mmap方式还是read方式;
设置videodevice成员设备文件名称,默认是 &#8220;/dev/video0&#8221;;
设置信号vd->signalquit=1,图像宽高:vd->hdrwidth=width;vd->hdrheight=height;
设置图像格式为VIDEO_PALETTE_JPEG:vd->formatIn = format;
获得色深:vd->bppIn = GetDepth (vd->formatIn);</p>

<hr />

<p>调用init_v4l():
=================进入init_v4l()================================================
init_v4l()是初始化v4l视频设备的函数,它首先通过系统调用open()打开视频设备,成功打开后主要执行下面几个步骤:</p>

<ul>
<li><ol>
<li>通过系统调用ioctl (vd->fd, VIDIOCGCAP, &amp;(vd->videocap))取得设备信息。读取struct video_capability中有关摄像头的信息,保存到vd->videocap中.</li>
</ol>
</li>
<li><ol>
<li>初始化图像.</li>
</ol>
</li>
</ul>


<p>ioctl (vd->fd, VIDIOCGPICT, &amp;vd->videopict);
带VIDIOCGPICT参数的ioctl调用会获取图像的属性,并保存在vd->videopict指向的结构体中.</p>

<ul>
<li><ol>
<li>读取ruct video chanel中有关设备通道的信息，保存到vd->videochan指向的结构体中。</li>
</ol>
</li>
</ul>


<p>ioctl (vd->fd, VIDIOCGCHAN, &amp;vd->videochan);</p>

<ul>
<li><ol>
<li>设置摄像头参数.</li>
</ol>
</li>
</ul>


<p>读取摄像头数据前,需要对摄像头进行设置,主要包括图像参数和分辨率.</p>

<pre><code>ioctl (vd-&gt;fd, VIDIOCSPICT, &amp;vd-&gt;videopict)
</code></pre>

<p>设置分辨率主要是对vd->videowin各分量进行修改,若为read方式,具体实现为:</p>

<pre><code>if (ioctl (vd-&gt;fd, VIDIOCGWIN, &amp;(vd-&gt;videowin)) &lt; 0)    // 获得捕获源的大小
    perror ("VIDIOCGWIN failed \n");
vd-&gt;videowin.height = vd-&gt;hdrheight;
vd-&gt;videowin.width = vd-&gt;hdrwidth;
if (ioctl (vd-&gt;fd, VIDIOCSWIN, &amp;(vd-&gt;videowin)) &lt; 0)
    perror ("VIDIOCSWIN failed \n");
</code></pre>

<ul>
<li><ol>
<li>摄像头设备文件映射初始化或read方式初始化</li>
</ol>
</li>
</ul>


<p>完成上述初始化设备工作后,就可以对访问到摄像头设备文件的内容了. 如果选用mmap()内存映射方式的话,下面的步骤将摄像头设备文件映射到进程内存,这样就可以直接读取映射了的这片内存,而不必read设备文件了:</p>

<p>a. 获取摄像头缓冲区帧信息:</p>

<pre><code>ioctl (vd-&gt;fd, VIDIOCGMBUF, &amp;(vd-&gt;videombuf));
</code></pre>

<p>该操作获取摄像头存储缓冲区的帧信息:包括帧的大小(size),最多支持的帧数(frames),每帧相对基址的偏移(offset). 这些参数都是由摄像头设备硬件决定的. 这些信息将被保存在videombuf结构体里面,下面的映射摄像头设备文件到内存操作马上就要用到了:</p>

<p>b. 映射摄像头设备文件到内存:</p>

<pre><code>vd-&gt;pFramebuffer =
            (unsigned char *) mmap (0, vd-&gt;videombuf.size, PROT_READ | PROT_WRITE,
                    MAP_SHARED, vd-&gt;fd, 0);
</code></pre>

<p>该操作把摄像头对应的设备文件映射到内存区. 该映射内容区可读可写并且不同进程间可共享. 帧的大小(vd->videombuf. size)是a步骤获取的. 该函数成功返回映像内存区的指针,该指针赋值给vd->pFramebuffer,失败时返回-1.</p>

<p>c. 视频图像捕捉测试:</p>

<pre><code>/* Grab frames 抓取一帧*/
if (ioctl(vd-&gt;fd, VIDIOCMCAPTURE, &amp;(vd-&gt;vmmap))) {
    perror ("cmcapture");
}
</code></pre>

<p>该操作捕捉一帧图像,获取图像信息到vmmap里. 它会根据vmmap中设置的属性参数(frame,height,width和format)通知驱动程序启动摄像头抓拍图像. 该操作是非阻塞的,是否截取完毕留给VDIOCSYNC来判断. 在init_v4l()这里只是为了测试是否可以成功捕获一帧图像,真正采集图像是在采集线程时执行v4lGrab()这个函数的时候.</p>

<p>以上是用mmap内存映射方式,如果采用直接读取摄像头设备文件的方式获取图像的话,将执行:</p>

<pre><code>els {
    /* read method */
    /* allocate the read buffer */
    vd-&gt;pFramebuffer = (unsigned char *) realloc(vd-&gt;pFramebuffer, \
            (size_t) vd-&gt;framesizeIn);
    /* 为pFrameffer分配内存 */

    if (ioctl (vd-&gt;fd, VIDIOCGWIN, &amp;(vd-&gt;videowin)) &lt; 0)    // 获得捕获源的大小
        perror("VIDIOCGWIN failed \n");
    vd-&gt;videowin.height = vd-&gt;hdrheight;
    vd-&gt;videowin.width = vd-&gt;hdrwidth;
    if (ioctl(vd-&gt;fd, VIDIOCSWIN, &amp;(vd-&gt;videowin)) &lt; 0)
        perror("VIDIOCSWIN failed \n");
}
</code></pre>

<p>摄像头设备文件映射初始化或read方式初始化完成后,返回init_videoIn().</p>

<p>=============从init_v4l() 返回========================================</p>

<hr />

<p>从init_v4l()返回到init_videoIn()后,分配vd->ptframe[i]空间.</p>

<pre><code>for (i = 0; i &lt; OUTFRMNUMB; i++) {
    vd-&gt;ptframe[i] = NULL;
    vd-&gt;ptframe[i] = (unsigned char *) realloc (vd-&gt;ptframe[i],\
            sizeof(struct frame_t) + (size_t) vd-&gt;framesizeIn );
    vd-&gt;framelock[i] = 0;
}
</code></pre>

<p>unsigned char* ptframe[4]：指向四个buffer缓冲数组，用来存放已压缩完成的图像数据.</p>

<h3>2.3 采集图像数据线程</h3>

<p>init_videoIn()执行完后返回main(),接下来创建采集视频图像的线程:</p>

<pre><code>pthread_create (&amp;w1, NULL, (void *) grab, NULL);
</code></pre>

<p>进入grab()函数:可以看到在死循环体里面调用v4lGrab()函数.
进入v4lGrab()函数,先判断一下是用mmap方法还是用read方法. 下面仅就mmap方法分析:</p>

<pre><code>ioctl (vd-&gt;fd, VIDIOCSYNC, &amp;vd-&gt;vmmap.frame);
</code></pre>

<p>这条语句是等待捕捉完这一帧图像,调用成功后表明一帧图像捕捉完毕,可以开始进行下一次图像捕捉. vd->vmmap.frame是当前捕捉到帧的序号.</p>

<p>接下来的是个循环睡眠等待:</p>

<pre><code>while((vd-&gt;framelock[vd-&gt;frame_cour] != 0) &amp;&amp; vd-&gt;signalquit)
            usleep(1000);
</code></pre>

<p>它是等待之后执行的另一个用来的发送采集到的图像数据给客户端的线程,直到它把这一帧图像完整地发送出去. 每隔1毫秒就检查一次是否发完. 如果不等待就执行下面的操作的话,那么还没发送完就把本来要发送的图像数据重写掉,采集到的数据没用上. 可以采用更好的同步机制&#8211;信号量来实现.</p>

<p>等到上一帧图像数据发送出去之后,这个线程等待直到获得一把线程互斥锁:</p>

<pre><code>pthread_mutex_lock (&amp;vd-&gt;grabmutex);
</code></pre>

<p>它把临界区资源vd->ptframe锁住,防止下面获取时间和拷贝数据到ptframe及设置一帧图像的头部时被别的线程抢占. 虽然在发送线程里并没有找到相关互斥锁的操作(这个应该是要加的),但为了扩展,有可能以后我们添加一些访问临界区vd->ptframe的线程时可以用它这把锁.</p>

<p>然后执行:</p>

<pre><code>  tems = ms_time();
</code></pre>

<p>tems获得的是距离UNIX的Epoch时间即:1970年1月1日0时0分0秒算起的毫秒数. 它可以用在视频图像的时间戳.
然后执行:</p>

<pre><code>jpegsize= convertframe(vd-&gt;ptframe[vd-&gt;frame_cour]+ sizeof(struct frame_t),
                vd-&gt;pFramebuffer + vd-&gt;videombuf.offsets[vd-&gt;vmmap.frame],
                vd-&gt;hdrwidth,vd-&gt;hdrheight,vd-&gt;formatIn,vd-&gt;framesizeIn);
</code></pre>

<p>跟踪进去可以看出要是视频图像格式是VIDEO_PALETTE_JPEG的话,直接将pFramebuffer中的数据拷贝到ptframe缓存中去，而不压缩处理,因为获得的就是已经压缩过的jpeg格式了(是硬件或底层驱动做了,一般USB摄像头对采集到的图像都作了jpeg格式压缩(内置JPEG硬件压缩)). 获得jpeg格式文件的大小是通过调用get_jpegsize()实现的. 进入get_jpegsize()可以发现,它利用了jpeg文件格式中是以0xFF 0xD9结尾的这个特性. ptframe里面的经压缩过的图像数据就是发送线程要发送出去的内容了.</p>

<p>pFramebuffer中的数据拷贝进ptframe完成后,就截取下一帧图像数据了:</p>

<pre><code>/* Grab frames */
if ((ioctl (vd-&gt;fd, VIDIOCMCAPTURE, &amp;(vd-&gt;vmmap))) &lt; 0) {
    perror ("cmcapture");
    if(debug) printf ("&gt;&gt;cmcapture err \n");
    erreur = -1;
}
    vd-&gt;vmmap.frame = (vd-&gt;vmmap.frame + 1) % vd-&gt;videombuf.frames;
    vd-&gt;frame_cour = (vd-&gt;frame_cour +1) % OUTFRMNUMB;
</code></pre>

<p>执行完后,跳出v4lGrab()函数体,返回到grab()去. 正常运行状态下,将不断循环调用v4lGrab()采集图像数据. 采集线程分析完毕.</p>

<h3>2.4 建立TCP套接字服务端,为图像数据发送线程做好准备</h3>

<p>回到main(),继续往下执行:</p>

<pre><code>serv_sock = open_sock(serverport);
</code></pre>

<p>跟踪进入open_sock()里面可以看到通过执行socket(),bind(),listen()建立了一个TCP套接字服务端并在指定端口上监听,等待客户端连接. 紧跟在socket()后面有一句:</p>

<pre><code>setsockopt(server_handle, SOL_SOCKET, SO_REUSEADDR, &amp;O_on, sizeof (int));
</code></pre>

<p>这个语句应该是为了允许启动多个服务端或多个servfox. 参见:<a href="http://blog.csdn.net/liusujian02/article/details/1944520">http://blog.csdn.net/liusujian02/article/details/1944520</a> (关于SO_REUSEADDR的使用说明)</p>

<p>执行完serv_sock = open_sock(serverport)这个语句之后,下一条语句是:</p>

<pre><code>signal(SIGPIPE, SIG_IGN);   /* Ignore sigpipe */
</code></pre>

<p>这是为了忽略SIGPIPE信号:若客户端关闭了和服务端的连接,但服务端依然试图发送图像数据给客户端(write to pipe with no readers),系统就会发出一个SIGPIPE信号,默认对SIGPIPE的处理是terminate(终止),那么负责发送图像数据的服务端就挂掉了,即使还有别的客户端连接. 这当然不是我们想要的,因此把我们要执行这句语句把SIGPIPE信号忽略掉.</p>

<h3>2.5 发送图像数据到客户端的线程</h3>

<p>接下来,是一个while(videoIn.signalquit)循环体,如果没有接收到退出信号,它就一直循环运行里面的语句:</p>

<pre><code>while (videoIn.signalquit) {
    sin_size = sizeof(struct sockaddr_in);

    /* 等待客户端的连接，如果没有连接就一直阻塞下去，
     * 如果有客户连接就创建一个线程，
     * 在新的套接口上与客户端进行数据交互
     */
    if ((new_sock = accept(serv_sock, (struct sockaddr *)&amp;their_addr, &amp;sin_size)) == -1) {
            continue;
    }
    syslog(LOG_ERR,"Got connection from %s\n",inet_ntoa(their_addr.sin_addr));
    printf("Got connection from %s\n",inet_ntoa(their_addr.sin_addr));
    pthread_create(&amp;server_th, NULL, (void *)service, &amp;new_sock);
}
</code></pre>

<p>之前建立的服务端一直监听等待客户端来连接,一旦有客户端connect()过来,服务端执行accept()建立连接后,就创建了发送图像数据到客户端的线程了:</p>

<pre><code>pthread_create(&amp;server_th, NULL, (void *)service, &amp;new_sock);
</code></pre>

<p>我们再进入这个线程执行的service()函数去分析:</p>

<hr />

<p>=============进入service()==============================</p>

<pre><code>/* initialize video setting */
    bright = upbright(&amp;videoIn);
    contrast = upcontrast(&amp;videoIn);
    bright = downbright(&amp;videoIn);
    contrast = downcontrast(&amp;videoIn);
</code></pre>

<p>上面所谓的初始话视频设置,是先增大一下亮度和对比度,在减小亮度和对比度恢复到原来的状态,顺便将亮度值保存在bright变量,将对比度值保存在contrast变量.
然后是一个死循环体:</p>

<pre><code>for ( ; ; ) {
    memset(&amp;message,0,sizeof(struct client_t));
    ret = read(sock,(unsigned char*)&amp;message,sizeof(struct client_t));
    ......
    if (message.updobright){
        switch (message.updobright){
            case 1: bright = upbright(&amp;videoIn);
                break;
            case 2: bright = downbright(&amp;videoIn);
                break;
        }
        ack = 1;
    } else if (message.updocontrast){
        switch (message.updocontrast){
            case 1: contrast = upcontrast(&amp;videoIn);
                break;
            case 2: contrast = downcontrast(&amp;videoIn);
                break;
        }
        ack = 1;
    } else if (message.updoexposure){
        switch (message.updoexposure){
            case 1: spcaSetAutoExpo(&amp;videoIn);
                break;
            case 2:;
                break;
        }
        ack = 1;
    } else if (message.updosize){ //compatibility FIX chg quality factor ATM
        switch (message.updosize){
            case 1: qualityUp(&amp;videoIn);
                break;
            case 2: qualityDown(&amp;videoIn);
                break;
        }
        ack = 1;
    } else if (message.fps){
        switch (message.fps){
            case 1: timeDown(&amp;videoIn);
                break;
            case 2: timeUp(&amp;videoIn);
                break;
        }
        ack = 1;
    } else if (message.sleepon){
        ack = 1;
    } else ack =0;
    while ((frameout == videoIn.frame_cour) &amp;&amp; videoIn.signalquit)
        usleep(1000);
    if (videoIn.signalquit){
        videoIn.framelock[frameout]++;
        headerframe = (struct frame_t *) videoIn.ptframe[frameout];
        headerframe-&gt;acknowledge = ack;
        headerframe-&gt;bright = bright;
        headerframe-&gt;contrast = contrast;
        headerframe-&gt;wakeup = wakeup;
        ret = write_sock(sock, (unsigned char *)headerframe, sizeof(struct frame_t)) ;
        /* 发送帧信息头 */

        if(!wakeup)
            ret = write_sock(sock,(unsigned char*)(videoIn.ptframe[frameout] + \
                        sizeof(struct frame_t)),headerframe-&gt;size);

        videoIn.framelock[frameout]--;
        frameout = (frameout+1)%4;
    } else {
        if(debug)
            printf("reader %d going out \n",*id);
        break;
    }
}
</code></pre>

<p>和客户端建立连接后,客户端会先将设置图像的信息发给服务端,因此上面代码,首先读取客户端对图像的设置,把设置信息存放在message结构体里,然后是根据message里的信息对采集图像的显示属性(如亮度bright,对比度contrast等)进行设置,具体操作是通过ioctl()调用底层驱动来完成对摄像头抓拍图像的显示设置.</p>

<p>设置完采集图像显示属性后,执行:</p>

<pre><code>while ((frameout == videoIn.frame_cour) &amp;&amp; videoIn.signalquit)
    usleep(1000);
</code></pre>

<p>frame_cour是指向压缩后的图像帧的指针数组下标,我们一共存储4帧(unsigned char *ptframe[4]),为了按顺序读取每一帧,就等待知道frameout和videoIn.frame_cour相等时才执行后面的发送操作,发送这帧图像完成后会执行frameout = (frameout+1)%4使得下一次发送下一帧图像. 个人觉得这里采取信号量的同步机制更好.
等采集线程完成一帧采集使得videoIn.frame_cour等于frameout之后(因为这里没有采用同步机制,有可能这一轮会落空),就开始执行发送这一帧图像给客户端的操作了:先将让headerframe指向帧信息头,然后发送headerframe指向的信息头给客户端,再发送剩下的图像数据. 这样就把完整的一帧图像发送给客户端了.
只要没有收到客户端退出的信号,以上的发送过程会循环执行.</p>

<p>当收到客户端退出的信息后,它就退出循环,执行close_sock(sock)关闭套接字,终止线程.</p>

<p>=============从service()返回=================================</p>

<hr />

<p>服务器发送图像线程终止后,只要进程没有退出信号还会在while (videoIn.signalquit)这个循环体继续,阻塞等待客户端的连接,重复上面的过程.</p>

<p>若videoIn.signalquit等于0了,就不再执行这个循环体,等待采集线程退出:pthread_join (w1, NULL);关闭套接字:close(serv_sock);回收以前分配的资源:close_v4l (&amp;videoIn);整个程序就正常退出了.</p>

<h2>3. servfox与底层驱动的接口</h2>

<p>前面说过,servfox只是个应用程序,它初始化设备,获取设备属性和图像属性,设置图像参数,捕捉图像数据,都是通过V4L1接口标准调用驱动的相关函数完成的.V4L1就是Video4Linux的版本1,Video4Linux已整合进Linux内核里面了.新版本是v4l2,它和v4l1不是完全兼容的.而V4L1已经是过时了.从Linux 2.6.38 内核就已经完全放弃了对v4l1的支持,因此不修改过的servfox不能在2.6.38以上的内核上运行了.不过有功能更强大的mjpeg-streamer来取代servfox.而mjpeg-streamer是基于v4l2接口的.</p>

<p>由于servfox体积小,在它上面进行扩展是很容易的,比如加入基于libjpeg库的本地解码jpeg显示到lcd屏的线程,加入截屏的线程等.</p>

<p>下面列出了servfox用到的一些v4l1的接口,如果非要把servfox移植到2.6.38的Linux内核上运行的话,必须修改这些v4l1的接口使之兼容于v4l2.</p>

<ul>
<li><p>摄像头驱动里要实现的ioctl()</p>

<ol>
<li><p>ioctl(vd->fd, VIDIOCSYNC, &amp;vd->vmmap.frame)</p>

<p> /<em> VIDIOCSYNC: Sync with mmap grabbing </em>/</p>

<p> /* 等待捕捉到这一帧图象.</p>

<ul>
<li>即等待一帧截取结束.</li>
<li>若成功，表明一帧截取已完成。</li>
<li>可以开始做下一次 VIDIOCMCAPTURE
*/</li>
</ul>
</li>
<li><p>if ((ioctl (vd->fd, VIDIOCMCAPTURE, &amp;(vd->vmmap))) &lt; 0)</p>

<p> /* Mmap方式下做视频截取的 VIDIOCMCAPTURE.</p>

<ul>
<li>若调用成功，开始一帧的截取，是非阻塞的，</li>
<li>是否截取完毕留给VIDIOCSYNC来判断
*/</li>
</ul>
</li>
<li><p>读video_picture中信息
 ioctl(vd->fd, VIDIOCGPICT, &amp;(vd->picture))；</p></li>
</ol>


<p>if (ioctl (vd->fd, VIDIOCGPICT, &amp;vd->videopict) &lt; 0)    /<em> Get picture properties </em>/
访问摄像头设备采集的图像的各种属性。然后通过访问结构体vd->videopict 就可以读出图像的各种信息。
vd->videopict中分量的值是可以改变的，实现方法为：先为分量赋新值，再调用VIDIOCSPICT. 如:</p>

<ol>
<li><p>  if (ioctl (vd->fd, VIDIOCGCAP, &amp;(vd->videocap)) == -1)      /<em> Get capabilities </em>/</p>

<pre><code>  exit_fatal ("Couldn't get videodevice capability");
</code></pre>

<p>  读video_capability 中信息
  ioctl(vd->fd, VIDIOCGCAP, &amp;(vd->capability))
  成功后可读取vd->capability各分量  eg.
  Printf（”maxwidth = %d”vd->capability.maxwidth）;</p></li>
<li><p>初始化channel:
if (ioctl (vd->fd, VIDIOCGCHAN, &amp;vd->videochan) == -1)     /<em> Get channel info (sources) </em>/</p>

<pre><code> // 用来取得和设置channel信息，例如使用那个输入源，制式等
</code></pre>

 {

<pre><code> if(debug) printf ("Hmm did not support Video_channel\n");
 vd-&gt;cameratype = UNOW;
</code></pre>

<p> }</p></li>
<li><p>初始化video_mbuf，以得到所映射的buffer的信息
 ioctl(vd->fd, VIDIOCGMBUF, &amp;(vd->mbuf))
 if (ioctl (vd->fd, VIDIOCGMBUF, &amp;(vd->videombuf)) &lt; 0)      /<em> Memory map buffer info </em>/
 {</p>

<pre><code> perror (" init VIDIOCGMBUF FAILED\n");
</code></pre>

<p> }</p>

<p> // 要确定是否捕捉到图象，要用到下一个命令。</p>

<pre><code>     if (ioctl (vd-&gt;fd, VIDIOCMCAPTURE, &amp;(vd-&gt;vmmap)))   /* Grab frames 抓取帧*/
     {
         perror ("cmcapture");
     }
</code></pre></li>
<li><p>if (ioctl (vd->fd, VIDIOCGWIN, &amp;(vd->videowin)) &lt; 0) // 获得捕获源的大小</p>

<pre><code>     perror ("VIDIOCGWIN failed \n");
</code></pre></li>
</ol>
</li>
<li><p>v4l2中的ioctl()的cmd:</p></li>
</ul>


<p>在进行V4L2开发中，一般会用到以下的命令标志符：</p>

<ol>
<li><p>VIDIOC_REQBUFS：分配内存</p></li>
<li><p>VIDIOC_QUERYBUF：把VIDIOC_REQBUFS中分配的数据缓存转换成物理地址</p></li>
<li><p>VIDIOC_QUERYCAP：查询驱动功能</p></li>
<li><p>VIDIOC_ENUM_FMT：获取当前驱动支持的视频格式</p></li>
<li><p>VIDIOC_S_FMT：设置当前驱动的频捕获格式</p></li>
<li><p>VIDIOC_G_FMT：读取当前驱动的频捕获格式</p></li>
<li><p>VIDIOC_TRY_FMT：验证当前驱动的显示格式</p></li>
<li><p>VIDIOC_CROPCAP：查询驱动的修剪能力</p></li>
<li><p>VIDIOC_S_CROP：设置视频信号的边框</p></li>
<li><p>VIDIOC_G_CROP：读取视频信号的边框</p></li>
<li><p>VIDIOC_QBUF：把数据从缓存中读取出来</p></li>
<li><p>VIDIOC_DQBUF：把数据放回缓存队列</p></li>
<li><p>VIDIOC_STREAMON：开始视频显示函数</p></li>
<li><p>VIDIOC_STREAMOFF：结束视频显示函数</p></li>
<li><p>VIDIOC_QUERYSTD：检查当前视频设备支持的标准，例如PAL或NTSC。</p></li>
</ol>


<p>这些IO调用，有些是必须的，有些是可选择的。</p>

<p>=========END=====================================================</p>

<ul>
<li><p>参考文献</p></li>
<li><p>基于S3C2440的嵌入式视频网络监控系统&#8211;柳亚东</p></li>
<li>基于嵌入式ARM的远程视频监控系统研究&#8211;李保国</li>
<li>基于ARM的嵌入式网络视频监控系统设计与实现&#8211;方卫民
&#8230;&#8230;</li>
</ul>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2011/06/18/e8afbbe998bfe59f8ee5b08fe8afb4e698afe4b880e7a78de4baabe58f97/">读阿城小说是一种享受</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2011-06-18T13:57:41+08:00" pubdate data-updated="true">Jun 18<span>th</span>, 2011</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>有时间的话，想读读阿城的小说。以前只读过他的《棋王》——多年前的事情了。
附上豆瓣上的一篇评论链接：<a href="http://book.douban.com/review/1421693/">http://book.douban.com/review/1421693/</a>
当然先要把那本《<a href="http://book.douban.com/subject/2175630/">8051微控制器和嵌入式系统</a>》看完。</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2011/02/28/e7a59ee5a587e79a84e7baa2e7bbbfe781af/">神奇的红绿灯</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2011-02-28T00:44:18+08:00" pubdate data-updated="true">Feb 28<span>th</span>, 2011</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>碰到这样的红绿灯，踌躇不前
<a href="http://hmgle.com/wp-content/uploads/2011/02/022611_002.jpg"><img src="http://hmgle.com/wp-content/uploads/2011/02/022611_002-300x240.jpg" alt="" /></a></p>

<p><a href="http://hmgle.com/wp-content/uploads/2011/02/022611_002.jpg"></a>
<a href="http://hmgle.com/wp-content/uploads/2011/02/022611_003.jpg"><img src="http://hmgle.com/wp-content/uploads/2011/02/022611_003-300x240.jpg" alt="" /></a>
总算还有正常的状态：
<a href="http://hmgle.com/wp-content/uploads/2011/02/022611_004.jpg"><img src="http://hmgle.com/wp-content/uploads/2011/02/022611_004-300x240.jpg" alt="" /></a></p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2011/02/15/hello-world/">Hello World！</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2011-02-15T11:58:26+08:00" pubdate data-updated="true">Feb 15<span>th</span>, 2011</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>这是导入之前在<a href="http://hi.baidu.com/hmgle">百度空间</a>的博文后在这里写的第一篇文章。之前的文章其实是先将百度空间的内容搬到<a href="http://hmgle.blogbus.com/">blogbus</a>后再从blogbus内导出xml文件然后再在wordpress里安个修正blogbus的不规范的xml文件的导入插件后最后才导进来的，不过图片什么的都没有了。像百度空间之类的连数据导出这个blog必备的基本功能都没有，令人匪夷所思。</p>

<p>其实我基本不写什么blog，人太懒，而且也不太喜欢回忆，它太沉重了。思考过的东西只在脑子里流过，记下来也没有啥价值的，权当为我百无聊赖的生活抹上胡乱的一笔。大家不要在这里逗留太久，这里可没有什么闪烁的光芒，尽管它的名字叫调和的微光，如果是学生应该多上点图书馆，要上也要关注些优秀的blog，比如国内的<a href="http://www.ruanyifeng.com/blog/">阮一峰的网志</a>。要玩的话应该玩些消耗体力培养竞争意识的运动，例如足球篮球之类的，千万别沉迷于滑板魔方之类的伪geek游戏。跑题了，关于这个blog的未来我还是希望它能闪烁些火光出来。我关注人文、科学、哲学及艺术，远离<strong><a href="http://en.wikipedia.org/wiki/Politics">politics</a>。</strong></p>

<p>关于火光，ukim在他的Heroes in my heart的帖子里引用过一个很好的事迹：在一次采访当中，作为数学家的Thom同两位古人类学家讨论问题。谈到远古的人们为什么要保存火种时，一个人类学家说，因为保存火种可以取暖御寒；另外一个人类学家说，因为保存火种可以烧出鲜美的肉食。而Thom说，因为夜幕来临之际，火光摇曳妩媚，灿烂多姿，是最美最美的。</p>
</div>
  
  


    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/blog/page/2/">&larr; Older</a>
    
    <a href="/blog/archives">Blog Archives</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2012/05/01/e6898be69cbae58fb7e7a081patch/">手机号码patch</a>
      </li>
    
      <li class="post">
        <a href="/blog/2012/03/17/arme5b9b3e58fb0e4b88be4bd8de59f9fe7bb93e69e84e4bd93e79a84e997aee9a298/">ARM平台下位域结构体的问题</a>
      </li>
    
      <li class="post">
        <a href="/blog/2012/01/12/e98092e5bd92e4b8ade79a84e694b9e8bf9b/">递归中的改进</a>
      </li>
    
      <li class="post">
        <a href="/blog/2011/12/26/e4b880e6aca1e99da2e8af95/">一次面试</a>
      </li>
    
      <li class="post">
        <a href="/blog/2011/12/11/e79c8be4ba86e8bf99e6a0b7e79a84makefile/">看了这样的makefile</a>
      </li>
    
  </ul>
</section>






  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2013 - hmgle -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  







  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = 'http://platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
